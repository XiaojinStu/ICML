exp,method,model,steps,lr,update_target,num_layers,eval_mode,token_total,token_correct_before,token_correct_after,token_acc_before,token_acc_after,token_acc@5_before,token_acc@5_after,seq_total,seq_correct_before,seq_correct_after,seq_acc_before,seq_acc_after,flipped,minutes,trainable_params,trainable_pct,trainable_layer_count,total_layers
attn_1,attn_1,Llama-3.2-1B-Instruct,5,0.001,attn,1,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,0.7431889772415161,10485760,0.8484898703235696,1,16
attn_2,attn_2,Llama-3.2-1B-Instruct,5,0.001,attn,2,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,0.8920540690422059,20971520,1.6969797406471392,2,16
attn_4,attn_4,Llama-3.2-1B-Instruct,5,0.001,attn,4,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,1.0862112681070963,41943040,3.3939594812942784,4,16
attn_8,attn_8,Llama-3.2-1B-Instruct,5,0.001,attn,8,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05813953488372093,30,2,2,0.06666666666666667,0.06666666666666667,0,1.3023669401804605,83886080,6.787918962588557,8,16
attn_all,attn_all,Llama-3.2-1B-Instruct,5,0.001,attn,all,ar,172,8,9,0.046511627906976744,0.05232558139534884,0.05232558139534884,0.06395348837209303,30,2,2,0.06666666666666667,0.06666666666666667,1,1.7307398716608684,167772160,13.575837925177114,16,16
baseline_all_all,baseline_all_all,Llama-3.2-1B-Instruct,5,0.001,all,all,ar,172,8,9,0.046511627906976744,0.05232558139534884,0.05232558139534884,0.0755813953488372,30,2,2,0.06666666666666667,0.06666666666666667,1,2.068655594189962,973144064,78.74516302771679,16,16
baseline_all_lm_head_all,baseline_all_lm_head_all,Llama-3.2-1B-Instruct,5,0.001,all+lm_head,all,ar,172,8,9,0.046511627906976744,0.05232558139534884,0.05232558139534884,0.06976744186046512,30,2,2,0.06666666666666667,0.06666666666666667,1,2.20904647509257,1235812352,99.9998342793222,16,16
baseline_attn_ln_all,baseline_attn_ln_all,Llama-3.2-1B-Instruct,5,0.001,attn+ln,all,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05813953488372093,30,2,2,0.06666666666666667,0.06666666666666667,0,1.8203645944595337,167837696,13.581140986866636,16,16
baseline_mlp_ln_all,baseline_mlp_ln_all,Llama-3.2-1B-Instruct,5,0.001,mlp+ln,all,ar,172,8,9,0.046511627906976744,0.05232558139534884,0.05232558139534884,0.06976744186046512,30,2,2,0.06666666666666667,0.06666666666666667,1,1.8534664432207744,805371904,65.16932510253967,16,16
last_layer_all,last_layer_all,Llama-3.2-1B-Instruct,5,0.001,all,1,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,0.7641881068547567,60821504,4.921572689232299,1,16
ln_all,ln_all,Llama-3.2-1B-Instruct,5,0.001,ln,all,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,1.6075039188067117,65536,0.00530306168952231,16,16
mlp_1,mlp_1,Llama-3.2-1B-Instruct,5,0.001,mlp,1,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,0.5232080419858297,50331648,4.072751377553134,1,16
mlp_2,mlp_2,Llama-3.2-1B-Instruct,5,0.001,mlp,2,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,0.8079721053441365,100663296,8.145502755106268,2,16
mlp_4,mlp_4,Llama-3.2-1B-Instruct,5,0.001,mlp,4,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,1.0068023920059204,201326592,16.291005510212536,4,16
mlp_8,mlp_8,Llama-3.2-1B-Instruct,5,0.001,mlp,8,ar,172,8,8,0.046511627906976744,0.046511627906976744,0.05232558139534884,0.05232558139534884,30,2,2,0.06666666666666667,0.06666666666666667,0,1.2932389775911968,402653184,32.58201102042507,8,16
mlp_all,mlp_all,Llama-3.2-1B-Instruct,5,0.001,mlp,all,ar,172,8,9,0.046511627906976744,0.05232558139534884,0.05232558139534884,0.0755813953488372,30,2,2,0.06666666666666667,0.06666666666666667,1,1.6717429876327514,805306368,65.16402204085014,16,16
